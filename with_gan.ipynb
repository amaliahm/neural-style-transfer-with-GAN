{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1567182,"sourceType":"datasetVersion","datasetId":925704}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision import transforms\n\n# Resize to 256x256 and normalize to [-1, 1]\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),  # Converts to [0,1]\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Now in [-1, 1]\n])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:29.244791Z","iopub.execute_input":"2025-04-29T16:58:29.244973Z","iopub.status.idle":"2025-04-29T16:58:35.919443Z","shell.execute_reply.started":"2025-04-29T16:58:29.244957Z","shell.execute_reply":"2025-04-29T16:58:35.918692Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport os\n\nclass ImageDataset(Dataset):\n    def __init__(self, root_A, root_B, transform=None):\n        self.transform = transform\n        self.files_A = sorted([os.path.join(root_A, f) for f in os.listdir(root_A) if f.endswith(\".jpg\")])\n        self.files_B = sorted([os.path.join(root_B, f) for f in os.listdir(root_B) if f.endswith(\".jpg\")])\n\n    def __len__(self):\n        return min(len(self.files_A), len(self.files_B))\n\n    def __getitem__(self, idx):\n        img_A = Image.open(self.files_A[idx]).convert(\"RGB\")\n        img_B = Image.open(self.files_B[idx]).convert(\"RGB\")\n\n        if self.transform:\n            img_A = self.transform(img_A)\n            img_B = self.transform(img_B)\n\n        return {\"A\": img_A, \"B\": img_B}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:35.920770Z","iopub.execute_input":"2025-04-29T16:58:35.921084Z","iopub.status.idle":"2025-04-29T16:58:35.927158Z","shell.execute_reply.started":"2025-04-29T16:58:35.921066Z","shell.execute_reply":"2025-04-29T16:58:35.926378Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndataset = ImageDataset(\"/kaggle/input/monet2photo/trainA\", \"/kaggle/input/monet2photo/trainB\", transform=transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:35.927891Z","iopub.execute_input":"2025-04-29T16:58:35.928135Z","iopub.status.idle":"2025-04-29T16:58:36.020492Z","shell.execute_reply.started":"2025-04-29T16:58:35.928111Z","shell.execute_reply":"2025-04-29T16:58:36.019834Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=1, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.021106Z","iopub.execute_input":"2025-04-29T16:58:36.021328Z","iopub.status.idle":"2025-04-29T16:58:36.025018Z","shell.execute_reply.started":"2025-04-29T16:58:36.021312Z","shell.execute_reply":"2025-04-29T16:58:36.024299Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"for i, batch in enumerate(dataloader):\n    print(batch[\"A\"].shape, batch[\"B\"].shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.027005Z","iopub.execute_input":"2025-04-29T16:58:36.027308Z","iopub.status.idle":"2025-04-29T16:58:36.171742Z","shell.execute_reply.started":"2025-04-29T16:58:36.027288Z","shell.execute_reply":"2025-04-29T16:58:36.171141Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"generator","metadata":{}},{"cell_type":"code","source":"# models/generator.py\nimport torch.nn as nn\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(dim, dim, 3),\n            nn.InstanceNorm2d(dim),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(dim, dim, 3),\n            nn.InstanceNorm2d(dim),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\nclass ResnetGenerator(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3, n_blocks=9):\n        super().__init__()\n        model = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(in_channels, 64, 7),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n        ]\n        # Downsample\n        in_features = 64\n        for _ in range(2):\n            out_features = in_features * 2\n            model += [\n                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True),\n            ]\n            in_features = out_features\n\n        # ResBlocks\n        for _ in range(n_blocks):\n            model += [ResnetBlock(in_features)]\n\n        # Upsample\n        for _ in range(2):\n            out_features = in_features // 2\n            model += [\n                nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True),\n            ]\n            in_features = out_features\n\n        model += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(64, out_channels, 7),\n            nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.172346Z","iopub.execute_input":"2025-04-29T16:58:36.172553Z","iopub.status.idle":"2025-04-29T16:58:36.180981Z","shell.execute_reply.started":"2025-04-29T16:58:36.172536Z","shell.execute_reply":"2025-04-29T16:58:36.180278Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"discriminator","metadata":{}},{"cell_type":"code","source":"# models/discriminator.py\nimport torch.nn as nn\n\nclass PatchDiscriminator(nn.Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        def block(in_feat, out_feat, norm=True):\n            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n            if norm:\n                layers.append(nn.InstanceNorm2d(out_feat))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *block(in_channels, 64, norm=False),\n            *block(64, 128),\n            *block(128, 256),\n            *block(256, 512),\n            nn.Conv2d(512, 1, 4, padding=1)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.181758Z","iopub.execute_input":"2025-04-29T16:58:36.182013Z","iopub.status.idle":"2025-04-29T16:58:36.197636Z","shell.execute_reply.started":"2025-04-29T16:58:36.181989Z","shell.execute_reply":"2025-04-29T16:58:36.196970Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"loss","metadata":{}},{"cell_type":"code","source":"adv_criterion = nn.MSELoss()  # For LSGAN (better stability)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.198217Z","iopub.execute_input":"2025-04-29T16:58:36.198459Z","iopub.status.idle":"2025-04-29T16:58:36.215303Z","shell.execute_reply.started":"2025-04-29T16:58:36.198442Z","shell.execute_reply":"2025-04-29T16:58:36.214820Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Cycle Consistency Loss","metadata":{}},{"cell_type":"code","source":"cycle_criterion = nn.L1Loss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.215902Z","iopub.execute_input":"2025-04-29T16:58:36.216127Z","iopub.status.idle":"2025-04-29T16:58:36.229981Z","shell.execute_reply.started":"2025-04-29T16:58:36.216111Z","shell.execute_reply":"2025-04-29T16:58:36.229360Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"identity loss","metadata":{}},{"cell_type":"code","source":"identity_criterion = nn.L1Loss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.230603Z","iopub.execute_input":"2025-04-29T16:58:36.230829Z","iopub.status.idle":"2025-04-29T16:58:36.243999Z","shell.execute_reply.started":"2025-04-29T16:58:36.230810Z","shell.execute_reply":"2025-04-29T16:58:36.243314Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"training loop","metadata":{}},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.244918Z","iopub.execute_input":"2025-04-29T16:58:36.245156Z","iopub.status.idle":"2025-04-29T16:58:36.325267Z","shell.execute_reply.started":"2025-04-29T16:58:36.245127Z","shell.execute_reply":"2025-04-29T16:58:36.324676Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"G_A2B = ResnetGenerator().to(device)\nG_B2A = ResnetGenerator().to(device)\nD_A = PatchDiscriminator().to(device)\nD_B = PatchDiscriminator().to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.326048Z","iopub.execute_input":"2025-04-29T16:58:36.326320Z","iopub.status.idle":"2025-04-29T16:58:36.765487Z","shell.execute_reply.started":"2025-04-29T16:58:36.326299Z","shell.execute_reply":"2025-04-29T16:58:36.764678Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import torch.optim as optim\n\n# Combine parameters of both generators\noptimizer_G = optim.Adam(\n    list(G_A2B.parameters()) + list(G_B2A.parameters()), \n    lr=0.0002, \n    betas=(0.5, 0.999)\n)\n\n# Optimizers for discriminators\noptimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.766280Z","iopub.execute_input":"2025-04-29T16:58:36.766515Z","iopub.status.idle":"2025-04-29T16:58:36.771699Z","shell.execute_reply.started":"2025-04-29T16:58:36.766499Z","shell.execute_reply":"2025-04-29T16:58:36.771002Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"lambda_identity = 5.0\nlambda_cycle = 10.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T16:58:36.773891Z","iopub.execute_input":"2025-04-29T16:58:36.774082Z","iopub.status.idle":"2025-04-29T16:58:36.785447Z","shell.execute_reply.started":"2025-04-29T16:58:36.774067Z","shell.execute_reply":"2025-04-29T16:58:36.784830Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Store loss history\nG_losses = []\nD_A_losses = []\nD_B_losses = []\nepoch_times = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:01:38.916986Z","iopub.execute_input":"2025-04-29T18:01:38.917525Z","iopub.status.idle":"2025-04-29T18:01:38.921557Z","shell.execute_reply.started":"2025-04-29T18:01:38.917500Z","shell.execute_reply":"2025-04-29T18:01:38.920818Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import time\n\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()  # Track start time of epoch\n    total_loss_G = 0\n    total_loss_D_A = 0\n    total_loss_D_B = 0\n    total_batches = len(dataloader)\n\n    for batch_idx, batch in enumerate(dataloader):\n        batch_start_time = time.time()  # Track start time of batch\n\n        real_A = batch[\"A\"].to(device)\n        real_B = batch[\"B\"].to(device)\n\n        # === Train Generators ===\n        optimizer_G.zero_grad()\n\n        # Identity loss\n        same_B = G_A2B(real_B)\n        same_A = G_B2A(real_A)\n        loss_id_A = identity_criterion(same_A, real_A) * lambda_identity\n        loss_id_B = identity_criterion(same_B, real_B) * lambda_identity\n\n        # GAN loss\n        fake_B = G_A2B(real_A)\n        pred_fake_B = D_B(fake_B)\n        loss_GAN_A2B = adv_criterion(pred_fake_B, torch.ones_like(pred_fake_B))\n\n        fake_A = G_B2A(real_B)\n        pred_fake_A = D_A(fake_A)\n        loss_GAN_B2A = adv_criterion(pred_fake_A, torch.ones_like(pred_fake_A))\n\n        # Cycle loss\n        rec_A = G_B2A(fake_B)\n        rec_B = G_A2B(fake_A)\n        loss_cycle_A = cycle_criterion(rec_A, real_A) * lambda_cycle\n        loss_cycle_B = cycle_criterion(rec_B, real_B) * lambda_cycle\n\n        # Total generator loss\n        loss_G = loss_id_A + loss_id_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A + loss_cycle_B\n        loss_G.backward()\n        optimizer_G.step()\n\n        # === Train Discriminators ===\n        optimizer_D_A.zero_grad()\n        pred_real_A = D_A(real_A)\n        pred_fake_A = D_A(fake_A.detach())\n        loss_D_real_A = adv_criterion(pred_real_A, torch.ones_like(pred_real_A))\n        loss_D_fake_A = adv_criterion(pred_fake_A, torch.zeros_like(pred_fake_A))\n        loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5\n        loss_D_A.backward()\n        optimizer_D_A.step()\n\n        optimizer_D_B.zero_grad()\n        pred_real_B = D_B(real_B)\n        pred_fake_B = D_B(fake_B.detach())\n        loss_D_real_B = adv_criterion(pred_real_B, torch.ones_like(pred_real_B))\n        loss_D_fake_B = adv_criterion(pred_fake_B, torch.zeros_like(pred_fake_B))\n        loss_D_B = (loss_D_real_B + loss_D_fake_B) * 0.5\n        loss_D_B.backward()\n        optimizer_D_B.step()\n\n        # Accumulate losses\n        total_loss_G += loss_G.item()\n        total_loss_D_A += loss_D_A.item()\n        total_loss_D_B += loss_D_B.item()\n\n        # Track time per batch\n        batch_time = time.time() - batch_start_time\n        remaining_batches = total_batches - (batch_idx + 1)\n        estimated_time_left = batch_time * remaining_batches\n        print(f\"Batch {batch_idx+1}/{total_batches} completed in {batch_time:.2f} seconds. Estimated time left: {estimated_time_left/60:.2f} minutes.\", end='\\r')\n\n    # After all batches in an epoch, print the total results\n    epoch_end_time = time.time()\n    epoch_duration = epoch_end_time - epoch_start_time\n    G_losses.append(total_loss_G / total_batches)\n    D_A_losses.append(total_loss_D_A / total_batches)\n    D_B_losses.append(total_loss_D_B / total_batches)\n    epoch_times.append(epoch_duration / 60)  # Save time in minutes\n\n    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] completed in {epoch_duration/60:.2f} minutes.\")\n    print(f\"  Generator Loss: {total_loss_G/total_batches:.4f}\")\n    print(f\"  Discriminator A Loss: {total_loss_D_A/total_batches:.4f}\")\n    print(f\"  Discriminator B Loss: {total_loss_D_B/total_batches:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T18:01:58.568500Z","iopub.execute_input":"2025-04-29T18:01:58.569021Z"}},"outputs":[{"name":"stdout","text":"Batch 1072/1072 completed in 0.31 seconds. Estimated time left: 0.00 minutes.\nEpoch [1/10] completed in 5.71 minutes.\n  Generator Loss: 6.6729\n  Discriminator A Loss: 0.1203\n  Discriminator B Loss: 0.1759\nBatch 1072/1072 completed in 0.31 seconds. Estimated time left: 0.00 minutes.\nEpoch [2/10] completed in 5.70 minutes.\n  Generator Loss: 6.5882\n  Discriminator A Loss: 0.1115\n  Discriminator B Loss: 0.1728\nBatch 1072/1072 completed in 0.31 seconds. Estimated time left: 0.00 minutes.\nEpoch [3/10] completed in 5.69 minutes.\n  Generator Loss: 6.5082\n  Discriminator A Loss: 0.1058\n  Discriminator B Loss: 0.1726\nBatch 1072/1072 completed in 0.31 seconds. Estimated time left: 0.00 minutes.\nEpoch [4/10] completed in 5.72 minutes.\n  Generator Loss: 6.4351\n  Discriminator A Loss: 0.0991\n  Discriminator B Loss: 0.1721\nBatch 857/1072 completed in 0.31 seconds. Estimated time left: 1.12 minutes.\r","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"save models","metadata":{}},{"cell_type":"code","source":"torch.save(G_A2B.state_dict(), \"G_A2B.pth\")\ntorch.save(G_B2A.state_dict(), \"G_B2A.pth\")\ntorch.save(D_A.state_dict(), \"D_A.pth\")\ntorch.save(D_B.state_dict(), \"D_B.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:58:53.417915Z","iopub.execute_input":"2025-04-29T17:58:53.418171Z","iopub.status.idle":"2025-04-29T17:58:53.583332Z","shell.execute_reply.started":"2025-04-29T17:58:53.418153Z","shell.execute_reply":"2025-04-29T17:58:53.582590Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"plotting","metadata":{}},{"cell_type":"code","source":"epochs = range(1, num_epochs + 1)\n\nplt.figure(figsize=(12, 6))\n\n# Plot Generator loss\nplt.plot(epochs, G_losses, label='Generator Loss', marker='o')\n\n# Plot Discriminator losses\nplt.plot(epochs, D_A_losses, label='Discriminator A Loss', marker='x')\nplt.plot(epochs, D_B_losses, label='Discriminator B Loss', marker='s')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Losses Over Epochs')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = range(1, num_epochs + 1)\n\nplt.figure(figsize=(12, 6))\nplt.plot(epochs, epoch_times, label='Epoch Duration (min)', marker='D', color='purple')\nplt.xlabel('Epoch')\nplt.ylabel('Time (minutes)')\nplt.title('Running Time per Epoch')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"evaluation","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    for batch in test_dataloader:\n        real_A = batch[\"A\"].to(device)\n        fake_B = G_A2B(real_A)\n        # Save or plot fake_B","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:55:39.069006Z","iopub.execute_input":"2025-04-29T17:55:39.069227Z","iopub.status.idle":"2025-04-29T17:55:39.093070Z","shell.execute_reply.started":"2025-04-29T17:55:39.069211Z","shell.execute_reply":"2025-04-29T17:55:39.092169Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2709026407.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_A2B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Save or plot fake_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"],"ename":"NameError","evalue":"name 'test_dataloader' is not defined","output_type":"error"}],"execution_count":16},{"cell_type":"markdown","source":"save generators and so","metadata":{}},{"cell_type":"code","source":"# Save the models after training\ntorch.save(G_A2B.state_dict(), '/kaggle/working/G_A2B.pth')  # Save Generator A to B\ntorch.save(G_B2A.state_dict(), '/kaggle/working/G_B2A.pth')  # Save Generator B to A\ntorch.save(D_A.state_dict(), '/kaggle/working/D_A.pth')      # Save Discriminator A\ntorch.save(D_B.state_dict(), '/kaggle/working/D_B.pth')      # Save Discriminator B\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T17:55:39.093542Z","iopub.status.idle":"2025-04-29T17:55:39.093795Z","shell.execute_reply.started":"2025-04-29T17:55:39.093651Z","shell.execute_reply":"2025-04-29T17:55:39.093661Z"}},"outputs":[],"execution_count":null}]}